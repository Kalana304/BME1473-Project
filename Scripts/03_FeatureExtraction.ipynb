{"cells":[{"cell_type":"markdown","metadata":{"id":"sA-UrWAqBS5l"},"source":["# Feature Extraction\n","\n","In this notebook, useful features are extracted for the final classification from outputs from the denoised EEG signal datasets. In this the following two methods will be used.\n","\n","[1] Time-Frequency Features - These are extracted using Wavelet Transformation where the parameters that will be analyzed would be following.\n","\n","  Parameters to consider: \n","  \n","    1. Mother Wavelet Function (Complex Morlet, DB, xx)\n","    2. Number of Levels (4, 6, 8)\n","\n","[2] Alternative - Theoretical Comparison (No Implementartion)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21865,"status":"ok","timestamp":1669779762784,"user":{"displayName":"Kalana Abeywardhana","userId":"14611642061052754052"},"user_tz":300},"id":"Uuho3KeHAbB7","outputId":"1b6c930f-9a62-4a73-e50b-718da74e4902"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15533,"status":"ok","timestamp":1669779778310,"user":{"displayName":"Kalana Abeywardhana","userId":"14611642061052754052"},"user_tz":300},"id":"5mlo3SyvA_f9","outputId":"f512ba6e-f965-48dd-cda2-f09aeac1cc94"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[K     |████████████████████████████████| 7.6 MB 5.2 MB/s \n","\u001b[K     |████████████████████████████████| 161 kB 4.8 MB/s \n","\u001b[K     |████████████████████████████████| 2.4 MB 58.7 MB/s \n","\u001b[?25hCloning into 'entropy'...\n","remote: Enumerating objects: 1487, done.\u001b[K\n","remote: Counting objects: 100% (10/10), done.\u001b[K\n","remote: Compressing objects: 100% (10/10), done.\u001b[K\n","remote: Total 1487 (delta 0), reused 0 (delta 0), pack-reused 1477\u001b[K\n","Receiving objects: 100% (1487/1487), 3.38 MiB | 3.44 MiB/s, done.\n","Resolving deltas: 100% (953/953), done.\n"]}],"source":["!pip install -q mne\n","!pip install -q wfdb pyEDFlib PyWavelets\n","!git clone https://github.com/raphaelvallat/entropy.git entropy/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rhbxDmErBCQO"},"outputs":[],"source":["import sys, os\n","\n","sys.path.append(os.path.join(os.getcwd(), \"drive/MyDrive/BME1473_Project\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oCOgZcjvBE_0"},"outputs":[],"source":["import glob            # for file locations\n","import pandas as pd     # dataframes\n","import numpy as np\n","import pickle\n","\n","import scipy.signal as signal\n","from pylab import *\n","from scipy.fft import fft, fftfreq, fftshift\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CgN40FBKBFcb"},"outputs":[],"source":["RESULTS_DIR = './drive/MyDrive/BME1473_Project/Results'\n","\n","Sub_Dir = ['F', 'S'] # Where F - Baseline Signals, S - Seizure Signal\n","sampling_freq = 173.73\n","dict_list = []"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X3erpmeFen8-"},"outputs":[],"source":["def dict2dataframe(data_dict, passfreq = None, forder = None, window = None, data_type = 'nonfilt'):\n","  labels = []\n","  data_frame = pd.DataFrame()\n","\n","  for data_dir in Sub_Dir:\n","    if data_type == 'nonfilt':\n","      sub_dict = data_dict[data_dir]\n","    elif data_type == 'firfilt':\n","      sub_dict = data_dict[data_dir][passfreq][forder][window]\n","    else:\n","      sub_dict = data_dict[data_dir][window]\n","      print(sub_dict.shape)\n","    labels += [data_dir for i in range(sub_dict.shape[0])]    \n","\n","    for i in range(sub_dict.shape[0]):\n","      data_frame = data_frame.append(pd.Series(sub_dict[i, :]), ignore_index=True)\n","\n","  data_frame['Label'] = labels\n","\n","  return data_frame"]},{"cell_type":"markdown","metadata":{"id":"rS--mO_FHbZa"},"source":["## Wavelet Transformation\n","\n","Wavelets can be used to analyse time series with non-stationary power at different frequency bands, express discontinuities caused by recording apparatus, and are useful for identifying and removing artefacts. \n","\n","Several oscillatory kernel-based wavelets are projected onto a signal, dividing the data into different frequency components which are each analysed in respect to their scale. A 'family' wavelet is a group of functions that is defined by stretching or shrinking a wavelet (dilation) and moving the wavelet to different positions in time (translation)."]},{"cell_type":"markdown","metadata":{"id":"mHQxN6Y_MYaE"},"source":["**Undecimated (Stationary) Wavelet Transform**\n","\n","Unlike DWT, where an odd or even decimation can be made, UDWT uses both odd and even transformations at each scale. UDWT is a more computationally intensive method than DWT, but can result in better discrimination between noise and activity, as well as more precise frequency localization."]},{"cell_type":"markdown","metadata":{"id":"MXwvoaFMJNUU"},"source":["***DWT Features Extracted***\n","\n","Based on the literature, 5 main features are derived from the wavelet transformation as follows:\n","\n","    1.Log-Sum of Wavelet Transform\n","    2.Mean of Absolute Values of the coefficients in each sub-band\n","    3.Average Power of the wavelet coefficients in each sub-band\n","    4.Standard Deviation of the coefficients in each sub-band\n","    5.Ratio of the Absolute Mean values of adjacent sub-bands"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-QETN_YV3siu"},"outputs":[],"source":["def data_index(feat_data, file_name, output = False):\n","    \n","    # get the file identifier from the file (e.g. F001)\n","    file_identifier = file_name.split('/')[-1].split('.')[0]\n","    # add this identifier to a column\n","    feat_data['file_id'] = file_identifier\n","    \n","    # if the file identifier has an S in...\n","    if re.findall('S', file_identifier):\n","        # make a class column with 'seizure' in\n","        feat_data['class'] = 'seizure'\n","    # ...otherwise...\n","    else:\n","        # .. make a class column with 'Baseline' in\n","        feat_data['class'] = 'baseline'\n","        \n","    \n","    # if the file identifier has a Z or O in...\n","    if re.findall('Z|O', file_identifier):\n","        # make a location column with 'surface' in\n","        feat_data['location'] = 'surface'\n","    # if the file identifier has an N in...\n","    elif re.findall('N', file_identifier):\n","        # make a location column with 'intracranial hippocampus' in\n","        feat_data['location'] = 'intracranial hippocampus'\n","    # if the file identifier has an S or F in...\n","    elif re.findall('F|S', file_identifier):\n","        # make a location column with 'intracranial epileptogenic zone' in\n","        feat_data['location'] = 'intracranial epileptogenic zone'\n","        \n","    # name the index\n","    feat_data.columns.name = 'feature'\n","    \n","    # add the file_id and class to the index\n","    feat_data = feat_data.set_index(['file_id', 'class', 'location'])\n","    # reorder the index so class is first, then file_id, then feature\n","    feat_data = feat_data.reorder_levels(['class', 'location', 'file_id'], axis='index')\n","    \n","    if output:\n","        display(feat_data)\n","        \n","    return feat_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mYU9tXkv6C-9"},"outputs":[],"source":["sys.path.append(os.path.join(os.getcwd(), \"./drive/MyDrive//BME1473_Project/Implementation\"))\n","from FeatureExtraction import Seizure_Features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_gbw_nmV2rBC"},"outputs":[],"source":["def featExtraction( data_frame, \n","                    sampling_freq, \n","                    save_path,\n","                    downsample = 1,\n","                    window_size = None,\n","                    overlap = None,\n","                    weighted = False,\n","                    features = [],\n","                    bandpasses = [],\n","                    wavelet = 'db4',\n","                    wavelet_transform = 'DWT',\n","                    levels = 6,\n","                    fft_band = [1, 48],\n","                    scale = False\n","                   ):\n","  feature_df = pd.DataFrame()\n","\n","  signal_data = data_frame.T.iloc[:-1].T\n","  nSignals, nSamples = signal_data.shape\n","  \n","  label_data = data_frame.T.iloc[-1].T\n","\n","  for i_sig in range(nSignals):\n","      # get the signal from the dataframe\n","      signal_ = signal_data.iloc[i_sig].tolist()\n","      signal_ = pd.DataFrame(signal_)\n","\n","      # setup the feature extraction function\n","      feat = Seizure_Features(  sf = sampling_freq, \n","                                downsample = downsample,\n","                                window_size = window_size,\n","                                overlap = overlap,\n","                                weighted = weighted,\n","                                feature_list = features,   # ['power', 'power_ratio', 'mean', 'mean_abs', 'std', 'ratio', 'LSWT', 'fft_corr', 'fft_eigen', 'time_corr', 'time_eigen', 'sample_entropy', 'spectral_entropy']\n","                                bandpasses = bandpasses,\n","                                bandpass_mean = False,\n","                                bandpass_ratios=[[[3,12],[2,30]],],\n","                                wavelet = wavelet,\n","                                wavelet_transform = wavelet_transform,\n","                                levels = levels,\n","                                fft_band = fft_band,\n","                                scale = scale,\n","                            )\n","\n","      # transform the data using the function\n","      part_x_feat = feat.transform(signal_.values, channel_names_list = ['CZ'])\n","\n","      # put the numpy output back into a pandas df\n","      part_x_feat = pd.DataFrame(part_x_feat, columns = feat.feature_names)\n","\n","      # re-index the data\n","      file_name = f'{label_data.iloc[i_sig]}_{(i_sig + 1) % 80 :02d}'\n","\n","      part_x_feat = data_index(part_x_feat, file_name)\n","\n","      # if there is no data in the feature data so far...\n","      if feature_df.empty:\n","          # then make this the feature dataframe...\n","          feature_df = part_x_feat\n","      else:\n","          # ...otherwise combine the two dataframes together down the index\n","          feature_df = pd.concat([feature_df, part_x_feat], axis='index')\n","\n","  # reset the index into columns (for easy saving)\n","  feature_df_save = feature_df.reset_index()\n","\n","  # save the dataframe to disk for later use\n","  os.makedirs(save_path, exist_ok=True)\n","  save_path = os.path.join(save_path, f'{wavelet}_{wavelet_transform}_{levels}.json.gzip')\n","  \n","  feature_df_save.to_json(save_path, \n","                          orient='index', \n","                          compression = 'gzip'\n","                         ) \n","  return feature_df_save"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b27UfzLfd5KB"},"outputs":[],"source":["sub_dir = 'denoised'\n","dataset = 'train_zca'\n","\n","file_path = os.path.join(RESULTS_DIR, sub_dir, dataset + '.pickle')\n","\n","with open(file_path, 'rb') as file_:\n","  data_dict = pickle.load(file_)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ErKbyTQ4p9IZ"},"outputs":[],"source":["data_frame = dict2dataframe(data_dict)"]},{"cell_type":"markdown","source":["### Feature extraction for different data sphering steps"],"metadata":{"id":"e_5uOCfZa9Vl"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FNdY0MS1nBkD"},"outputs":[],"source":["features = ['power', 'power_ratio', 'mean', 'mean_abs', 'std', 'ratio', 'LSWT', 'sample_entropy', 'spectral_entropy']\n","bandpasses = [[2,4],[4,8],[8,12], [12,30], [30, 48]]\n","\n","wavelets = ['db4', 'db6', 'Haar']\n","\n","wavelet_transforms = ['DWT', 'UDWT']\n","level = [6]\n","\n","save_path = f'./drive/MyDrive/BME1473_Project/FeatureData/{sub_dir}/{dataset}'\n","os.makedirs(save_path, exist_ok = True)\n","\n","for wavelet in wavelets:\n","  for wavelet_transform in wavelet_transforms:\n","    for levels in level:\n","      feature_dataframe = featExtraction(  data_frame = data_frame, \n","                                          sampling_freq = sampling_freq, \n","                                          save_path = save_path,\n","                                          downsample = 1,\n","                                          window_size = None,\n","                                          overlap = None,\n","                                          weighted = False,\n","                                          features = features,\n","                                          bandpasses = bandpasses,\n","                                          wavelet = wavelet,\n","                                          wavelet_transform = wavelet_transform,\n","                                          levels = levels,\n","                                          fft_band = [1, 48],\n","                                          scale = False\n","                                        )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Xp8LRl19WHr"},"outputs":[],"source":["def filtfeatures(data_frame, sub_dir, dataset, passfreq, forder, window):\n","  wavelets = ['db4', 'db6', 'Haar']\n","\n","  wavelet_transforms = ['DWT', 'UDWT']\n","  level = [6]\n","  save_path = f'./drive/MyDrive/BME1473_Project/FeatureData/{sub_dir}/{dataset}/{passfreq}_{forder}_{window}'\n","  os.makedirs(save_path, exist_ok = True)\n","\n","  for wavelet in wavelets:\n","    for wavelet_transform in wavelet_transforms:\n","      for levels in level:\n","        feature_dataframe = featExtraction(  data_frame = data_frame, \n","                                            sampling_freq = sampling_freq, \n","                                            save_path = save_path,\n","                                            downsample = 1,\n","                                            window_size = None,\n","                                            overlap = None,\n","                                            weighted = False,\n","                                            features = features,\n","                                            bandpasses = bandpasses,\n","                                            wavelet = wavelet,\n","                                            wavelet_transform = wavelet_transform,\n","                                            levels = levels,\n","                                            fft_band = [1, 48],\n","                                            scale = False\n","                                          )\n","  return feature_dataframe"]},{"cell_type":"markdown","source":["### Feature extraction for FIR filtered datasets"],"metadata":{"id":"dQePgK3bbIWq"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"jnNwNrRy8FmR"},"outputs":[],"source":["sub_dir = 'fir_filtering'\n","dataset = 'fir_filt_original_test'\n","\n","file_path = os.path.join(RESULTS_DIR, sub_dir, dataset + '.pickle')\n","\n","with open(file_path, 'rb') as file_:\n","  data_dict = pickle.load(file_)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rc84sXQ68UTm"},"outputs":[],"source":["pass_freqs = list(data_dict['S'].keys())\n","forders = list(data_dict['S'][pass_freqs[0]].keys())\n","windows = list(data_dict['S'][pass_freqs[0]][forders[0]].keys())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":150,"status":"ok","timestamp":1669782611123,"user":{"displayName":"Kalana Abeywardhana","userId":"14611642061052754052"},"user_tz":300},"id":"a39FUk9I8rCi","outputId":"85b06396-d226-4660-b4fd-ec50728fe135"},"outputs":[{"name":"stdout","output_type":"stream","text":["[35, 40, 45, 50]\n","[16, 32, 64, 128]\n","['boxcar', 'hamming', 'blackman']\n"]}],"source":["print(pass_freqs)\n","print(forders)\n","print(windows)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"dfB9bHiRwniE"},"outputs":[],"source":["for passfreq in pass_freqs[:-1]:\n","  for forder in forders:\n","    for window in windows:\n","      data_frame = dict2dataframe(data_dict, passfreq, forder, window, data_type = 'firfilt')\n","      feature_dataframe = filtfeatures(data_frame, sub_dir, dataset, passfreq, forder, window)\n"]},{"cell_type":"markdown","source":["### Feature extraction for DWT denoised EEG signals"],"metadata":{"id":"O6SSVL74bTMD"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"IRnPJK1-MScZ"},"outputs":[],"source":["def dwtfeatures(data_frame, sub_dir, dataset, dwt_):\n","  wavelets = ['db4', 'db6', 'Haar']\n","\n","  wavelet_transforms = ['DWT', 'UDWT']\n","  level = [6]\n","  save_path = f'./drive/MyDrive/BME1473_Project/FeatureData/{sub_dir}/{dataset}/{dwt_}'\n","  os.makedirs(save_path, exist_ok = True)\n","\n","  for wavelet in wavelets:\n","    for wavelet_transform in wavelet_transforms:\n","      for levels in level:\n","        feature_dataframe = featExtraction(  data_frame = data_frame, \n","                                            sampling_freq = sampling_freq, \n","                                            save_path = save_path,\n","                                            downsample = 1,\n","                                            window_size = None,\n","                                            overlap = None,\n","                                            weighted = False,\n","                                            features = features,\n","                                            bandpasses = bandpasses,\n","                                            wavelet = wavelet,\n","                                            wavelet_transform = wavelet_transform,\n","                                            levels = levels,\n","                                            fft_band = [1, 48],\n","                                            scale = False\n","                                          )\n","  return feature_dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qG5d-eCxJxPU"},"outputs":[],"source":["sub_dir = 'dwt_filtering'\n","dataset = 'dwt_synth_original_train'\n","\n","file_path = os.path.join(RESULTS_DIR, sub_dir, dataset + '.pickle')\n","\n","with open(file_path, 'rb') as file_:\n","  data_dict = pickle.load(file_)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4OklV9pvLp_j"},"outputs":[],"source":["wavelets = list(data_dict['S'].keys())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":294223,"status":"ok","timestamp":1669526907967,"user":{"displayName":"Kalana Abeywardhana","userId":"14611642061052754052"},"user_tz":300},"id":"HlwfIn86LshM","outputId":"90e30d18-bc83-447d-9a1d-063565242612"},"outputs":[{"name":"stdout","output_type":"stream","text":["(80, 4097)\n","(80, 4097)\n","(80, 4097)\n","(80, 4097)\n","(80, 4097)\n","(80, 4097)\n","(80, 4097)\n","(80, 4097)\n","(80, 4097)\n","(80, 4097)\n"]}],"source":["for wavelet in wavelets:\n","  data_frame = dict2dataframe(data_dict, None, None, wavelet, data_type = 'dwtfilt')\n","  feature_dataframe = dwtfeatures(data_frame, sub_dir, dataset, wavelet)"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPWk3H+/i/TC4LkI7H+TKcY"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}